{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxLDVyzxECRGF624ODx5LJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install nltk networkx scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eIT23GQt0Chu","executionInfo":{"status":"ok","timestamp":1771956101816,"user_tz":-330,"elapsed":5488,"user":{"displayName":"SagnikBasu_NLP","userId":"06651014294091949391"}},"outputId":"011c825e-36f3-4107-b121-386eb1c76ce4"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"]}]},{"cell_type":"code","source":["import nltk\n","import numpy as np\n","import networkx as nx\n","import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def summarize_text(text, summary_length=2):\n","\n","    text = re.sub(r'\\s+', ' ', text)\n","    sentences = sent_tokenize(text)\n","\n","    stop_words = stopwords.words('english')\n","\n","    def preprocess(sentence):\n","        sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n","        words = sentence.lower().split()\n","        words = [word for word in words if word not in stop_words]\n","        return \" \".join(words)\n","\n","    clean_sentences = [preprocess(sentence) for sentence in sentences]\n","\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform(clean_sentences)\n","\n","    similarity_matrix = (tfidf_matrix * tfidf_matrix.T).toarray()\n","\n","    nx_graph = nx.from_numpy_array(similarity_matrix)\n","    scores = nx.pagerank(nx_graph)\n","\n","    ranked_sentences = sorted(\n","        ((scores[i], i, s) for i, s in enumerate(sentences)),\n","        reverse=True\n","    )\n","\n","    summary_length = min(summary_length, len(sentences))\n","\n","    selected_sentences = sorted(\n","        ranked_sentences[:summary_length],\n","        key=lambda x: x[1]\n","    )\n","\n","    summary = \" \".join([sentence[2] for sentence in selected_sentences])\n","\n","    return summary\n","\n","\n","# ---- USER INPUT ----\n","text = input(\"Enter your paragraph:\\n\")\n","length = int(input(\"How many sentences should the summary contain? \"))\n","\n","print(\"\\nSummary:\\n\")\n","print(summarize_text(text, length))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LH2aDX0q0FNH","executionInfo":{"status":"ok","timestamp":1771956127052,"user_tz":-330,"elapsed":15334,"user":{"displayName":"SagnikBasu_NLP","userId":"06651014294091949391"}},"outputId":"74099120-6852-4870-d33e-4ad001dfeb6e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Enter your paragraph:\n","Artificial Intelligence is rapidly transforming industries across the world.  It is being used in healthcare, finance, education, and transportation.  Machine learning, a subset of AI, allows computers to learn from data without being explicitly programmed.  Deep learning has further enhanced AI capabilities by enabling neural networks to process complex patterns.  However, AI systems require large amounts of data to function effectively.  There are also concerns about data privacy and algorithmic bias.  Researchers are working to make AI systems more transparent and ethical.\n","How many sentences should the summary contain? 2\n","\n","Summary:\n","\n","Machine learning, a subset of AI, allows computers to learn from data without being explicitly programmed. However, AI systems require large amounts of data to function effectively.\n"]}]},{"cell_type":"markdown","source":["**Sample Input:**\n","\n","Artificial Intelligence is rapidly transforming industries across the world.\n","It is being used in healthcare, finance, education, and transportation.\n","Machine learning, a subset of AI, allows computers to learn from data without being explicitly programmed.\n","Deep learning has further enhanced AI capabilities by enabling neural networks to process complex patterns.\n","However, AI systems require large amounts of data to function effectively.\n","There are also concerns about data privacy and algorithmic bias.\n","Researchers are working to make AI systems more transparent and ethical."],"metadata":{"id":"yXNewXX90RA6"}},{"cell_type":"code","source":[],"metadata":{"id":"MfvKjSrk0T2C"},"execution_count":null,"outputs":[]}]}